{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ACKS Chatbot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzPxX-ZW8uN0","executionInfo":{"status":"ok","timestamp":1693111114571,"user_tz":-480,"elapsed":2801,"user":{"displayName":"Kaiyue Shi","userId":"08522383292819172175"}},"outputId":"7325401c-2e7f-4edc-86c6-920f0ea18f95"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/ACKS Chatbot\n"]}]},{"cell_type":"code","source":["pip install openai"],"metadata":{"id":"g7sRmgBTM0RC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693111125250,"user_tz":-480,"elapsed":6153,"user":{"displayName":"Kaiyue Shi","userId":"08522383292819172175"}},"outputId":"5b497055-9273-4ad7-8b0d-452e5411216e"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.9)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"]}]},{"cell_type":"code","execution_count":85,"metadata":{"id":"Q-a7Svm5lccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693116337633,"user_tz":-480,"elapsed":11078,"user":{"displayName":"Kaiyue Shi","userId":"08522383292819172175"}},"outputId":"3ef1357e-267a-4427-ca6a-ed8ead6660f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 new messages.\n"]}],"source":["from pip._vendor import requests\n","import openai\n","from messages import *\n","from occupancy_level import *\n","import libsearch\n","\n","api_url = \"https://api.telegram.org/bot6465057227:AAGancKfZb-ie490jDgeBBoeoLdSA5fewos/getUpdates\" #URL that stores all the user messages\n","response = requests.get(api_url)\n","\n","bot_token = '6465057227:AAGancKfZb-ie490jDgeBBoeoLdSA5fewos'\n","openai.api_key = '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'\n","\n","\n","def sendtext_to_user(user_id, bot_message):\n","    bot_chatID = user_id\n","    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n","\n","\n","    response = requests.get(send_text)\n","\n","    return response.json() # to check whether the message is sent succuessfully\n","\n","\n","if response.status_code == 200:\n","    data = response.json()  # Convert the response to JSON format\n","    result = data[\"result\"] # all messages in the bot from user\n","    # the actual content are stored in: result[0][\"message\"][\"from\"]\n","\n","    message_dict = {}\n","    for entry in result:\n","        user_id = entry[\"message\"][\"from\"][\"id\"]\n","        message = entry[\"message\"][\"text\"]\n","        message_dict[user_id] = message\n","\n","\n","    # The path to the file storing the entry count\n","    entry_count_file = \"entry_count.txt\"\n","\n","    # Read the stored entry count (if available)\n","    try:\n","        with open(entry_count_file, \"r\") as f:\n","            stored_entry_count = int(f.read())\n","    except FileNotFoundError:\n","        stored_entry_count = 0\n","\n","    # Update the entry count to the current count of updates\n","    current_entry_count = len(result)\n","\n","    # Compare stored entry count with current entry count\n","    if current_entry_count > stored_entry_count:\n","        new_entries = current_entry_count - stored_entry_count\n","        print(f\"There are {new_entries} new messages.\")\n","\n","        # If there are new messages\n","        new_messages_by_id = {}  # Dictionary to store new messages by user ID\n","\n","\n","        for update in result[-new_entries:]:\n","            message = update[\"message\"]\n","            user_id = message[\"from\"][\"id\"]\n","\n","            text = message[\"text\"]\n","\n","            if user_id not in new_messages_by_id:\n","                new_messages_by_id[user_id] = []\n","            new_messages_by_id[user_id].append(text)\n","\n","        # Do something with the new messages\n","        for user_id, messages in new_messages_by_id.items():\n","            # sendtext_to_user(str(user_id), \"hey, you!\")\n","            ## GPT-3.5-turbo\n","\n","            user_prompt = messages[0]\n","\n","\n","            if user_prompt == \"/lks\":\n","                sendtext_to_user(str(user_id), get_library_numbers(\"lks\"))\n","\n","            elif user_prompt == \"/kgc\":\n","                sendtext_to_user(str(user_id), get_library_numbers(\"kgc\"))\n","\n","            elif user_prompt == \"/start\":\n","                sendtext_to_user(str(user_id), STARTER_MESSAGE)\n","\n","            elif user_prompt == \"/help\":\n","                sendtext_to_user(str(user_id), HELP)\n","\n","            elif user_prompt.startswith(\"/libsearch \"):\n","                lib_prompt = user_prompt.split(\" \", 1)[1]\n","                sendtext_to_user(str(user_id), libsearch.parse_gpt(lib_prompt))\n","\n","            elif user_prompt.startswith(\"/lksbot \"):\n","              bot_prompt = user_prompt.split(\" \", 1)[1]\n","\n","              ## LKS tuned GPT search\n","              lks_prompt = [{\n","                  \"role\" : \"user\",\n","                  \"content\" : bot_prompt\n","                  }]\n","              response = openai.ChatCompletion.create(\n","              model = \"ft:gpt-3.5-turbo-0613:smulib::7rtBDMkN\",\n","              messages = lks_prompt,\n","              temperature = 0.3,\n","              max_tokens = 2000)\n","\n","              GPT_reply = \"lksBot reply: \" + response['choices'][0]['message']['content']\n","              sendtext_to_user(str(user_id), GPT_reply)\n","\n","\n","            else:\n","\n","                ## plain chatGPT search\n","                prompt = [{\n","                    \"role\" : \"user\",\n","                    \"content\" : user_prompt\n","                    }]\n","                response = openai.ChatCompletion.create(\n","                model = \"gpt-3.5-turbo\",\n","                messages = prompt,\n","                temperature = 1,\n","                max_tokens = 2000)\n","\n","                GPT_reply = \"GPT reply: \" + response['choices'][0]['message']['content']\n","                sendtext_to_user(str(user_id), GPT_reply)\n","\n","\n","    else:\n","        print(\"No new messages.\")\n","\n","    # Save the current entry count to the file\n","    with open(entry_count_file, \"w\") as f:\n","        f.write(str(current_entry_count))\n","\n","else:\n","    print(\"Failed to retrieve data from the API.\")"]},{"cell_type":"code","source":["# ## plain chatGPT search\n","# test_prompt = \"hi there, who are you?\"\n","\n","# prompt = [{\n","#   \"role\" : \"user\",\n","#   \"content\" : test_prompt\n","#   }]\n","# response = openai.ChatCompletion.create(\n","# model = \"ft:gpt-3.5-turbo-0613:smulib::7rtBDMkN\",\n","# messages = prompt,\n","# temperature = 0.3,\n","# max_tokens = 2000)\n","\n","# GPT_reply = \"lksBot reply: \" + response['choices'][0]['message']['content']\n","# sendtext_to_user(str(user_id), GPT_reply)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tsgobcp8tQ2H","executionInfo":{"status":"ok","timestamp":1693106794314,"user_tz":-480,"elapsed":6570,"user":{"displayName":"Kaiyue Shi","userId":"08522383292819172175"}},"outputId":"f8731788-d559-4199-f89b-46c7d2d75e4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ok': True,\n"," 'result': {'message_id': 146,\n","  'from': {'id': 6338445284,\n","   'is_bot': True,\n","   'first_name': 'SMU Library ChatBot',\n","   'username': 'smu_librarychatbot'},\n","  'chat': {'id': 5159983766,\n","   'first_name': 'SKY',\n","   'username': 'kyshi97',\n","   'type': 'private'},\n","  'date': 1693106793,\n","  'text': \"GPT reply: I am the library, even though I don't have a physical presence.\"}}"]},"metadata":{},"execution_count":13}]}]}